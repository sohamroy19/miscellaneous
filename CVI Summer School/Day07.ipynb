{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DaySeven.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb0f23ed0cd041d99843994a6d9ae8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c27a9c8784044349d6972d8d212ad18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b07545d1fc443f39c153362972ff1e6",
              "IPY_MODEL_2a1369580da24d6c97280790c37886c6"
            ]
          }
        },
        "1c27a9c8784044349d6972d8d212ad18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b07545d1fc443f39c153362972ff1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa2ff63e52f240c9bea9bf7dbb6bc63a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21af973265254bcf9ed8865d562590d1"
          }
        },
        "2a1369580da24d6c97280790c37886c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0169bc8b43844ca088cbb8f4f1176a02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:18&lt;00:00, 2.49MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34d856e50ae54ae48a0a16646617d3b4"
          }
        },
        "aa2ff63e52f240c9bea9bf7dbb6bc63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21af973265254bcf9ed8865d562590d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0169bc8b43844ca088cbb8f4f1176a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34d856e50ae54ae48a0a16646617d3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "540b00266f2c441f8bc704a9c58d7db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53305a83bb0c4f4db4b640819ad856da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0d23c798980406083c40ffaf886b71c",
              "IPY_MODEL_9fd56ecf286e4683900ae551a9988e11"
            ]
          }
        },
        "53305a83bb0c4f4db4b640819ad856da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0d23c798980406083c40ffaf886b71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d8266700e5dd4fb88236390d1d64cd0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99c4e14cf67648bbacb008635da102c5"
          }
        },
        "9fd56ecf286e4683900ae551a9988e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_773afb72fb934999a58029ec4cda0c78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:05&lt;00:00, 29597518.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c150e33b149a45878bb9f403e455ced8"
          }
        },
        "d8266700e5dd4fb88236390d1d64cd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99c4e14cf67648bbacb008635da102c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "773afb72fb934999a58029ec4cda0c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c150e33b149a45878bb9f403e455ced8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diyGYvVzkzVq"
      },
      "source": [
        "#TASK 1\n",
        "\n",
        "1.   PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data. Use the `torchvision.datasets` to import preloaded Dataset [`CIFAR`](https://pytorch.org/vision/stable/datasets.html#cifar) to train and then finetune the ResNet18 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKOUbypXjO0u"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJgrC7WpnGIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "bb0f23ed0cd041d99843994a6d9ae8bf",
            "1c27a9c8784044349d6972d8d212ad18",
            "1b07545d1fc443f39c153362972ff1e6",
            "2a1369580da24d6c97280790c37886c6",
            "aa2ff63e52f240c9bea9bf7dbb6bc63a",
            "21af973265254bcf9ed8865d562590d1",
            "0169bc8b43844ca088cbb8f4f1176a02",
            "34d856e50ae54ae48a0a16646617d3b4"
          ]
        },
        "outputId": "6a445da4-f1a8-47a4-a274-5fcff26078bd"
      },
      "source": [
        "#Loading in Resnet18 pre-trained Model\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "#You can use ```dir(models)``` to see various models available for Transfer Learning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb0f23ed0cd041d99843994a6d9ae8bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46830571.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjzwC2bQn2gb"
      },
      "source": [
        "#Freeze the model weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSoIrAU6n76g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8abe393-356d-4bac-e17b-c7323e55865d"
      },
      "source": [
        "#Add the fully connected layer\n",
        "#Here replace num_classes with number of classes you are classifying \n",
        "\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "model.fc = nn.Linear(512, 10)\n",
        "model.to(device=\"cuda\")\n",
        "\n",
        "#Check model summary once to ensure the changes you made"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1egDcBTmg_Hs",
        "outputId": "72dbf916-53ea-45df-abf5-e5a45f1bce6a"
      },
      "source": [
        "summary(model, input_size=(3, 32, 32), batch_size=500)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [500, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2          [500, 64, 32, 32]             128\n",
            "              ReLU-3          [500, 64, 32, 32]               0\n",
            "         MaxPool2d-4          [500, 64, 16, 16]               0\n",
            "            Conv2d-5          [500, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-6          [500, 64, 16, 16]             128\n",
            "              ReLU-7          [500, 64, 16, 16]               0\n",
            "            Conv2d-8          [500, 64, 16, 16]          36,864\n",
            "       BatchNorm2d-9          [500, 64, 16, 16]             128\n",
            "             ReLU-10          [500, 64, 16, 16]               0\n",
            "       BasicBlock-11          [500, 64, 16, 16]               0\n",
            "           Conv2d-12          [500, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-13          [500, 64, 16, 16]             128\n",
            "             ReLU-14          [500, 64, 16, 16]               0\n",
            "           Conv2d-15          [500, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-16          [500, 64, 16, 16]             128\n",
            "             ReLU-17          [500, 64, 16, 16]               0\n",
            "       BasicBlock-18          [500, 64, 16, 16]               0\n",
            "           Conv2d-19           [500, 128, 8, 8]          73,728\n",
            "      BatchNorm2d-20           [500, 128, 8, 8]             256\n",
            "             ReLU-21           [500, 128, 8, 8]               0\n",
            "           Conv2d-22           [500, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-23           [500, 128, 8, 8]             256\n",
            "           Conv2d-24           [500, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-25           [500, 128, 8, 8]             256\n",
            "             ReLU-26           [500, 128, 8, 8]               0\n",
            "       BasicBlock-27           [500, 128, 8, 8]               0\n",
            "           Conv2d-28           [500, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-29           [500, 128, 8, 8]             256\n",
            "             ReLU-30           [500, 128, 8, 8]               0\n",
            "           Conv2d-31           [500, 128, 8, 8]         147,456\n",
            "      BatchNorm2d-32           [500, 128, 8, 8]             256\n",
            "             ReLU-33           [500, 128, 8, 8]               0\n",
            "       BasicBlock-34           [500, 128, 8, 8]               0\n",
            "           Conv2d-35           [500, 256, 4, 4]         294,912\n",
            "      BatchNorm2d-36           [500, 256, 4, 4]             512\n",
            "             ReLU-37           [500, 256, 4, 4]               0\n",
            "           Conv2d-38           [500, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-39           [500, 256, 4, 4]             512\n",
            "           Conv2d-40           [500, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-41           [500, 256, 4, 4]             512\n",
            "             ReLU-42           [500, 256, 4, 4]               0\n",
            "       BasicBlock-43           [500, 256, 4, 4]               0\n",
            "           Conv2d-44           [500, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-45           [500, 256, 4, 4]             512\n",
            "             ReLU-46           [500, 256, 4, 4]               0\n",
            "           Conv2d-47           [500, 256, 4, 4]         589,824\n",
            "      BatchNorm2d-48           [500, 256, 4, 4]             512\n",
            "             ReLU-49           [500, 256, 4, 4]               0\n",
            "       BasicBlock-50           [500, 256, 4, 4]               0\n",
            "           Conv2d-51           [500, 512, 2, 2]       1,179,648\n",
            "      BatchNorm2d-52           [500, 512, 2, 2]           1,024\n",
            "             ReLU-53           [500, 512, 2, 2]               0\n",
            "           Conv2d-54           [500, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-55           [500, 512, 2, 2]           1,024\n",
            "           Conv2d-56           [500, 512, 2, 2]         131,072\n",
            "      BatchNorm2d-57           [500, 512, 2, 2]           1,024\n",
            "             ReLU-58           [500, 512, 2, 2]               0\n",
            "       BasicBlock-59           [500, 512, 2, 2]               0\n",
            "           Conv2d-60           [500, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-61           [500, 512, 2, 2]           1,024\n",
            "             ReLU-62           [500, 512, 2, 2]               0\n",
            "           Conv2d-63           [500, 512, 2, 2]       2,359,296\n",
            "      BatchNorm2d-64           [500, 512, 2, 2]           1,024\n",
            "             ReLU-65           [500, 512, 2, 2]               0\n",
            "       BasicBlock-66           [500, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-67           [500, 512, 1, 1]               0\n",
            "           Linear-68                  [500, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 6,858\n",
            "Non-trainable params: 11,167,104\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 5.86\n",
            "Forward/backward pass size (MB): 2564.49\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 2612.98\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHMBSI5sodWR"
      },
      "source": [
        "#Define your transformations to be applied on the images here\n",
        "\n",
        "train = transforms.Compose([\n",
        "    transforms.RandomApply(transforms=[transforms.Pad(2, padding_mode='symmetric'),\n",
        "                                       transforms.RandomAffine(degrees=10, translate=(0.05,0.05), scale=(0.8,1))],\n",
        "                           p=0.3),\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomPosterize(3, p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "    transforms.RandomGrayscale(p=0.1,),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4yH2jVupCQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "540b00266f2c441f8bc704a9c58d7db7",
            "53305a83bb0c4f4db4b640819ad856da",
            "c0d23c798980406083c40ffaf886b71c",
            "9fd56ecf286e4683900ae551a9988e11",
            "d8266700e5dd4fb88236390d1d64cd0c",
            "99c4e14cf67648bbacb008635da102c5",
            "773afb72fb934999a58029ec4cda0c78",
            "c150e33b149a45878bb9f403e455ced8"
          ]
        },
        "outputId": "ecf48067-2504-4dc8-c755-d938f6c01c9a"
      },
      "source": [
        "#Import the CIFAR apply the transformations you created above\n",
        "#You can access the link given in question statement to check syntax for importing the dataset\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"./datasets\", train=True, transform=train, download=True)\n",
        "val_data = torchvision.datasets.CIFAR10(root=\"./datasets\", train=False, transform=val, download=True)\n",
        "\n",
        "#Remember to split the dataset into train_dataset and val_dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540b00266f2c441f8bc704a9c58d7db7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOaEQtsEptTl"
      },
      "source": [
        "#Create DataLoaders for you train and val Datasets\n",
        "train_dl = DataLoader(train_data, batch_size = 500, shuffle = True, num_workers = 2, pin_memory = True)\n",
        "val_dl = DataLoader(val_data, batch_size = 500, num_workers = 2, pin_memory = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "gOMX8GTJqG_Q",
        "outputId": "f050fdd9-d364-49a6-df01-26a2799c296d"
      },
      "source": [
        "'''print(your_dataset_name.classes[label])\n",
        "to check the label of the images imported'''\n",
        "\n",
        "img, label = train_data[4]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print(\"label:\", label, \"=>\", train_data.classes[label])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "label: 1 => automobile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QlptjXGqcut"
      },
      "source": [
        "'''Define your train function here\n",
        "you may exclude the timer and scheduler'''\n",
        "\n",
        "def train(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name=\"best.pt\",\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=20,\n",
        "          print_every=2):\n",
        "    \n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "    valid_max_acc = 0\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "    \n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        \n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Get model outputs and calculate loss\n",
        "            output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        model.epochs += 1\n",
        "\n",
        "        # Don't need to keep track of gradients\n",
        "        with torch.no_grad():\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for data, target in valid_loader:\n",
        "                # Tensors to gpu\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "\n",
        "                # Validation loss\n",
        "                loss = criterion(output, target)\n",
        "                # Multiply average loss times the number of examples in batch\n",
        "                valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                _, pred = torch.max(output, dim=1)\n",
        "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "                # Multiply average accuracy times the number of examples\n",
        "                valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Calculate average losses\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "            # Calculate average accuracy\n",
        "            train_acc = train_acc / len(train_loader.dataset)\n",
        "            valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "            \n",
        "\n",
        "            # Print training and validation results\n",
        "            if (epoch + 1) % print_every == 0:\n",
        "                print(\n",
        "                    f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                )\n",
        "                print(\n",
        "                    f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
        "                )\n",
        "\n",
        "            # Save the model if validation loss decreases\n",
        "            if valid_loss < valid_loss_min:\n",
        "                # Save model\n",
        "                torch.save(model.state_dict(), save_file_name)\n",
        "                # Track improvement\n",
        "                epochs_no_improve = 0\n",
        "                valid_loss_min = valid_loss\n",
        "                valid_best_acc = valid_acc\n",
        "                best_epoch = epoch\n",
        "\n",
        "            # Otherwise increment count of epochs with no improvement\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                # Trigger early stopping\n",
        "                if epochs_no_improve >= max_epochs_stop:\n",
        "                    print(\n",
        "                        f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "                    )\n",
        "\n",
        "                    # Load the best state dict\n",
        "                    model.load_state_dict(torch.load(save_file_name))\n",
        "                    # Attach the optimizer\n",
        "                    model.optimizer = optimizer\n",
        "\n",
        "                    \n",
        "                    return model\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    return model\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4aijCH0qia8"
      },
      "source": [
        "'''define the criterion,optimizer and scheduler(if used) parameters here'''\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5nnKkz7qyMd",
        "outputId": "a31a8d5e-a7b6-44aa-f077-5d22bbaa7fa5"
      },
      "source": [
        "'''run the model'''\n",
        "\n",
        "model = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    save_file_name=\"best.pt\",\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=1\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training from Scratch.\n",
            "\n",
            "\n",
            "Epoch: 0 \tTraining Loss: 2.0918 \tValidation Loss: 1.8283\n",
            "\t\tTraining Accuracy: 25.05%\t Validation Accuracy: 34.83%\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 1.8510 \tValidation Loss: 1.7136\n",
            "\t\tTraining Accuracy: 34.16%\t Validation Accuracy: 39.64%\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 1.7744 \tValidation Loss: 1.6600\n",
            "\t\tTraining Accuracy: 36.66%\t Validation Accuracy: 40.90%\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 1.7357 \tValidation Loss: 1.5971\n",
            "\t\tTraining Accuracy: 38.64%\t Validation Accuracy: 43.32%\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 1.6913 \tValidation Loss: 1.5578\n",
            "\t\tTraining Accuracy: 40.24%\t Validation Accuracy: 45.39%\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 1.6663 \tValidation Loss: 1.5230\n",
            "\t\tTraining Accuracy: 41.18%\t Validation Accuracy: 47.16%\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 1.6287 \tValidation Loss: 1.4810\n",
            "\t\tTraining Accuracy: 42.42%\t Validation Accuracy: 49.02%\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 1.6025 \tValidation Loss: 1.4468\n",
            "\t\tTraining Accuracy: 43.64%\t Validation Accuracy: 49.87%\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 1.5717 \tValidation Loss: 1.4243\n",
            "\t\tTraining Accuracy: 44.72%\t Validation Accuracy: 50.99%\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 1.5397 \tValidation Loss: 1.4016\n",
            "\t\tTraining Accuracy: 46.20%\t Validation Accuracy: 52.39%\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 1.5125 \tValidation Loss: 1.3297\n",
            "\t\tTraining Accuracy: 47.35%\t Validation Accuracy: 54.59%\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 1.4825 \tValidation Loss: 1.2825\n",
            "\t\tTraining Accuracy: 48.21%\t Validation Accuracy: 56.16%\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 1.4645 \tValidation Loss: 1.2446\n",
            "\t\tTraining Accuracy: 49.03%\t Validation Accuracy: 57.71%\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 1.4319 \tValidation Loss: 1.2236\n",
            "\t\tTraining Accuracy: 50.16%\t Validation Accuracy: 58.14%\n",
            "\n",
            "Epoch: 14 \tTraining Loss: 1.4137 \tValidation Loss: 1.2281\n",
            "\t\tTraining Accuracy: 50.69%\t Validation Accuracy: 58.18%\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 1.4097 \tValidation Loss: 1.2102\n",
            "\t\tTraining Accuracy: 50.95%\t Validation Accuracy: 58.52%\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 1.3898 \tValidation Loss: 1.1868\n",
            "\t\tTraining Accuracy: 51.43%\t Validation Accuracy: 59.62%\n",
            "\n",
            "Epoch: 17 \tTraining Loss: 1.3823 \tValidation Loss: 1.2047\n",
            "\t\tTraining Accuracy: 52.04%\t Validation Accuracy: 58.67%\n",
            "\n",
            "Epoch: 18 \tTraining Loss: 1.3702 \tValidation Loss: 1.1825\n",
            "\t\tTraining Accuracy: 52.60%\t Validation Accuracy: 59.75%\n",
            "\n",
            "Epoch: 19 \tTraining Loss: 1.3594 \tValidation Loss: 1.1521\n",
            "\t\tTraining Accuracy: 53.03%\t Validation Accuracy: 60.88%\n",
            "\n",
            "Epoch: 20 \tTraining Loss: 1.3564 \tValidation Loss: 1.1482\n",
            "\t\tTraining Accuracy: 52.87%\t Validation Accuracy: 61.02%\n",
            "\n",
            "Epoch: 21 \tTraining Loss: 1.3454 \tValidation Loss: 1.1374\n",
            "\t\tTraining Accuracy: 53.23%\t Validation Accuracy: 61.11%\n",
            "\n",
            "Epoch: 22 \tTraining Loss: 1.3419 \tValidation Loss: 1.1271\n",
            "\t\tTraining Accuracy: 53.59%\t Validation Accuracy: 61.93%\n",
            "\n",
            "Epoch: 23 \tTraining Loss: 1.3366 \tValidation Loss: 1.1172\n",
            "\t\tTraining Accuracy: 53.61%\t Validation Accuracy: 61.96%\n",
            "\n",
            "Epoch: 24 \tTraining Loss: 1.3377 \tValidation Loss: 1.2083\n",
            "\t\tTraining Accuracy: 53.80%\t Validation Accuracy: 58.54%\n",
            "\n",
            "Epoch: 25 \tTraining Loss: 1.3225 \tValidation Loss: 1.0935\n",
            "\t\tTraining Accuracy: 54.27%\t Validation Accuracy: 62.91%\n",
            "\n",
            "Epoch: 26 \tTraining Loss: 1.3126 \tValidation Loss: 1.0618\n",
            "\t\tTraining Accuracy: 54.37%\t Validation Accuracy: 63.73%\n",
            "\n",
            "Epoch: 27 \tTraining Loss: 1.3039 \tValidation Loss: 1.0809\n",
            "\t\tTraining Accuracy: 54.53%\t Validation Accuracy: 63.37%\n",
            "\n",
            "Epoch: 28 \tTraining Loss: 1.2978 \tValidation Loss: 1.0560\n",
            "\t\tTraining Accuracy: 54.83%\t Validation Accuracy: 63.88%\n",
            "\n",
            "Epoch: 29 \tTraining Loss: 1.2922 \tValidation Loss: 1.0649\n",
            "\t\tTraining Accuracy: 55.15%\t Validation Accuracy: 63.73%\n",
            "\n",
            "Best epoch: 28 with loss: 1.06 and acc: 63.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coejSsPbskK1",
        "outputId": "875f6d6f-9ddc-4346-e546-842fc04b5f17"
      },
      "source": [
        "'''Unfreeze all the layers and finetune the model to increase accuracy as model gets updated for relevancy towards the dataset'''\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model = train(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    save_file_name=\"best.pt\",\n",
        "    max_epochs_stop=5,\n",
        "    n_epochs=30,\n",
        "    print_every=1\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has been trained for: 30 epochs.\n",
            "\n",
            "\n",
            "Epoch: 0 \tTraining Loss: 0.8573 \tValidation Loss: 0.5426\n",
            "\t\tTraining Accuracy: 69.97%\t Validation Accuracy: 81.58%\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 0.5852 \tValidation Loss: 0.4331\n",
            "\t\tTraining Accuracy: 79.51%\t Validation Accuracy: 85.28%\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 0.4847 \tValidation Loss: 0.3809\n",
            "\t\tTraining Accuracy: 83.14%\t Validation Accuracy: 87.35%\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 0.4142 \tValidation Loss: 0.3472\n",
            "\t\tTraining Accuracy: 85.38%\t Validation Accuracy: 88.21%\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 0.3735 \tValidation Loss: 0.3344\n",
            "\t\tTraining Accuracy: 86.82%\t Validation Accuracy: 88.66%\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 0.3379 \tValidation Loss: 0.3082\n",
            "\t\tTraining Accuracy: 88.17%\t Validation Accuracy: 89.82%\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.3083 \tValidation Loss: 0.3011\n",
            "\t\tTraining Accuracy: 89.21%\t Validation Accuracy: 89.80%\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 0.2835 \tValidation Loss: 0.3074\n",
            "\t\tTraining Accuracy: 90.09%\t Validation Accuracy: 89.95%\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 0.2604 \tValidation Loss: 0.2937\n",
            "\t\tTraining Accuracy: 90.83%\t Validation Accuracy: 90.43%\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 0.2455 \tValidation Loss: 0.2927\n",
            "\t\tTraining Accuracy: 91.36%\t Validation Accuracy: 90.47%\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 0.2346 \tValidation Loss: 0.3026\n",
            "\t\tTraining Accuracy: 91.80%\t Validation Accuracy: 90.07%\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 0.2143 \tValidation Loss: 0.2893\n",
            "\t\tTraining Accuracy: 92.32%\t Validation Accuracy: 90.66%\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 0.2065 \tValidation Loss: 0.2889\n",
            "\t\tTraining Accuracy: 92.76%\t Validation Accuracy: 90.66%\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 0.1914 \tValidation Loss: 0.2905\n",
            "\t\tTraining Accuracy: 93.38%\t Validation Accuracy: 90.98%\n",
            "\n",
            "Epoch: 14 \tTraining Loss: 0.1802 \tValidation Loss: 0.2874\n",
            "\t\tTraining Accuracy: 93.78%\t Validation Accuracy: 90.81%\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 0.1744 \tValidation Loss: 0.2908\n",
            "\t\tTraining Accuracy: 93.82%\t Validation Accuracy: 90.97%\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 0.1665 \tValidation Loss: 0.2979\n",
            "\t\tTraining Accuracy: 94.17%\t Validation Accuracy: 90.85%\n",
            "\n",
            "Epoch: 17 \tTraining Loss: 0.1600 \tValidation Loss: 0.2907\n",
            "\t\tTraining Accuracy: 94.49%\t Validation Accuracy: 91.15%\n",
            "\n",
            "Epoch: 18 \tTraining Loss: 0.1502 \tValidation Loss: 0.2916\n",
            "\t\tTraining Accuracy: 94.83%\t Validation Accuracy: 91.07%\n",
            "\n",
            "Epoch: 19 \tTraining Loss: 0.1424 \tValidation Loss: 0.2961\n",
            "\t\tTraining Accuracy: 95.01%\t Validation Accuracy: 91.23%\n",
            "\n",
            "Early Stopping! Total epochs: 19. Best epoch: 14 with loss: 0.29 and acc: 91.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQwGbJS7uw-I"
      },
      "source": [
        "#TASK 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZBajf_zobS0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import ast\n",
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "WyyrRJgsOE9Z",
        "outputId": "52bd4044-98c0-4288-844e-343f33e5057f"
      },
      "source": [
        "# Load the datasets\n",
        "# reading CSV file\n",
        "data_iou = pd.read_csv(\"https://raw.githubusercontent.com/AdityaDas-IITM/SummerSchool-CV-Implementation-2021/main/Dataset%20for%20IOU%20%26%20NMS%20implementation/iou_testcases.csv\")\n",
        "data_iou"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test_case_number</th>\n",
              "      <th>Box_1</th>\n",
              "      <th>Box_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_case_1</td>\n",
              "      <td>[199, 422, 477, 474]</td>\n",
              "      <td>[31, 419, 204, 436]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_case_2</td>\n",
              "      <td>[345, 367, 449, 502]</td>\n",
              "      <td>[335, 333, 374, 452]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_case_3</td>\n",
              "      <td>[350, 147, 492, 20]</td>\n",
              "      <td>[462, 157, 478, 357]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_case_4</td>\n",
              "      <td>[215, 251, 446, 425]</td>\n",
              "      <td>[126, 463, 360, 510]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Test_case_number                 Box_1                 Box_2\n",
              "0      Test_case_1  [199, 422, 477, 474]   [31, 419, 204, 436]\n",
              "1      Test_case_2  [345, 367, 449, 502]  [335, 333, 374, 452]\n",
              "2      Test_case_3   [350, 147, 492, 20]  [462, 157, 478, 357]\n",
              "3      Test_case_4  [215, 251, 446, 425]  [126, 463, 360, 510]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "KG6qWUBcAj2s",
        "outputId": "9937ed77-ef09-41ca-9652-ce6fd0f37df7"
      },
      "source": [
        "# Load the datasets\n",
        "# reading CSV file\n",
        "data_nms = pd.read_csv(\"https://raw.githubusercontent.com/AdityaDas-IITM/SummerSchool-CV-Implementation-2021/main/Dataset%20for%20IOU%20%26%20NMS%20implementation/nms_testcases.csv\")\n",
        "data_nms"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test_case_number</th>\n",
              "      <th>Box_1</th>\n",
              "      <th>Box_2</th>\n",
              "      <th>Box_3</th>\n",
              "      <th>Box_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_case_1</td>\n",
              "      <td>[200, 100, 300, 300, 0.95]</td>\n",
              "      <td>[220, 110, 320, 310, 0.85]</td>\n",
              "      <td>[180, 90, 280, 290, 0.85]</td>\n",
              "      <td>[210, 120, 310, 320, 0.65]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_case_2</td>\n",
              "      <td>[200, 100, 400, 200, 0.65]</td>\n",
              "      <td>[220, 110, 420, 210, 0.85]</td>\n",
              "      <td>[180, 90, 380, 190, 0.5]</td>\n",
              "      <td>[210, 120, 410, 220, 0.6]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_case_3</td>\n",
              "      <td>[100, 150, 330, 290, 0.68]</td>\n",
              "      <td>[90, 175, 320, 310, 0.9]</td>\n",
              "      <td>[350, 90, 450, 290, 0.85]</td>\n",
              "      <td>[340, 110, 440, 310, 0.75]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_case_4</td>\n",
              "      <td>[100, 100, 200, 300, 0.95]</td>\n",
              "      <td>[150, 110, 250, 310, 0.85]</td>\n",
              "      <td>[200, 90, 300, 290, 0.85]</td>\n",
              "      <td>[250, 120, 350, 320, 0.63]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Test_case_number  ...                       Box_4\n",
              "0      Test_case_1  ...  [210, 120, 310, 320, 0.65]\n",
              "1      Test_case_2  ...   [210, 120, 410, 220, 0.6]\n",
              "2      Test_case_3  ...  [340, 110, 440, 310, 0.75]\n",
              "3      Test_case_4  ...  [250, 120, 350, 320, 0.63]\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_bKlMttOEUa"
      },
      "source": [
        "# Convert the pandas dataframe into lists\n",
        "listOfdata = data_iou.to_numpy().tolist()\n",
        "\n",
        "#Create list of bounding box coordinates for each of the test cases:\n",
        "iou_test_case_1 = [ast.literal_eval(listOfdata[0][1]), ast.literal_eval(listOfdata[0][2])]\n",
        "iou_test_case_2 = [ast.literal_eval(listOfdata[1][1]), ast.literal_eval(listOfdata[1][2])]\n",
        "iou_test_case_3 = [ast.literal_eval(listOfdata[2][1]), ast.literal_eval(listOfdata[2][2])]\n",
        "iou_test_case_4 = [ast.literal_eval(listOfdata[3][1]), ast.literal_eval(listOfdata[3][2])]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk6289F-Be-o"
      },
      "source": [
        "# Convert the pandas dataframe into lists\n",
        "listOfDFRows = data_nms.to_numpy().tolist()\n",
        "\n",
        "#Create list of bounding box coordinates for each of the test cases:\n",
        "nms_test_case_1 = [ast.literal_eval(listOfDFRows[0][1]), ast.literal_eval(listOfDFRows[0][2]), ast.literal_eval(listOfDFRows[0][3]), ast.literal_eval(listOfDFRows[0][4])]\n",
        "nms_test_case_2 = [ast.literal_eval(listOfDFRows[1][1]), ast.literal_eval(listOfDFRows[1][2]), ast.literal_eval(listOfDFRows[1][3]), ast.literal_eval(listOfDFRows[1][4])]\n",
        "nms_test_case_3 = [ast.literal_eval(listOfDFRows[2][1]), ast.literal_eval(listOfDFRows[2][2]), ast.literal_eval(listOfDFRows[2][3]), ast.literal_eval(listOfDFRows[2][4])]\n",
        "nms_test_case_4 = [ast.literal_eval(listOfDFRows[3][1]), ast.literal_eval(listOfDFRows[3][2]), ast.literal_eval(listOfDFRows[3][3]), ast.literal_eval(listOfDFRows[3][4])]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "JO7w7X1zPQ-t",
        "outputId": "ae8b1436-3436-40d8-f2d8-644326a824bd"
      },
      "source": [
        "# Visualize the boxes for one of the test cases\n",
        "img = np.zeros([512,512,3], dtype = np.uint8)\n",
        "box1, box2= iou_test_case_1[0], iou_test_case_1[1]\n",
        "cv2.rectangle(img, (box1[0], box1[1]), (box1[2], box1[3]), color = (0,255,0))#green\n",
        "cv2.rectangle(img, (box2[0], box2[1]), (box2[2], box2[3]), color = (0,0,255))#red\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAADxElEQVR4nO3cMQ6DMBAAQYj4/5dJn4IoioyBnelorCssrXHhZQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPhqHbr6PnR17mPsPgMuSABYbAO4qtfsAQCYY5s9AE/0ceZf/QXAj065NhUAxlgPP4EDZx2YXAEBRAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBA1PDH4LwCWeTpN4Ao2Yd/eA0UgKEEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIGqbPQAPtc8eAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC4lDdYAApwZcNmJAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F613225E6D0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hnlwOwAFuDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "d74cd62b-fb14-4d62-f98f-9adbdcd47552"
      },
      "source": [
        "# Visualize the boxes for one of the test cases\n",
        "img = np.zeros([512,512,3] ,dtype = np.uint8)\n",
        "box1, box2, box3, box4 = nms_test_case_1[0], nms_test_case_1[1], nms_test_case_1[2], nms_test_case_1[3]\n",
        "cv2.rectangle(img, (box1[0], box1[1]), (box1[2], box1[3]), color = (0,255,0))\n",
        "cv2.rectangle(img, (box2[0], box2[1]), (box2[2], box2[3]), color = (0,0,255))\n",
        "cv2.rectangle(img, (box3[0], box3[1]), (box3[2], box3[3]), color = (255,0,0))\n",
        "cv2.rectangle(img, (box4[0], box4[1]), (box4[2], box4[3]), color = (255,255,255)) \n",
        "\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAFlklEQVR4nO3dwYrCMBRAUTv4/7/c2c5sorSWpN5ztiUSC+ZC4OHjAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwrm32BljZPnsD9+LXBHwPAXifd8X9/MzeAABzCABAlAAARAkAQJQAAEQJAECUAABECQBA1HP2BvhStbmo7dxXNkTMDALAZWqH2uHvW4sly3AFBBAlAABRAgAQJQAAUQIAECUAAFECABAlAABRBsFYzh3nok4NAp+bmKvN2/FBAsCK7nioHd/zfnzxHWPJOlwBAUQJAECUAABECQBAlAAARAkAQJQAAEQJAECUQTAm2PcXA0z3nG86sevh0m2742AccG9XnWjjADj9/z38wnfFKlwBAUQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQNRz9gZY3H5w3Xb8k18vBT5BABg4cRTv49Wjxy+WAh/iCgggSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogyCcZnxEPHg6XZ8ABl4nwBwjfEs78thX6PAcD1XQABRAgAQJQAAUQIAECUAAFECABAlAABRAgAQZRCMFRkE/svb4CICwHJMAf/lH5K5jisggCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgyCMYc+26+FQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Dq//wUs0Uog9JIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F6132250DD0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-nExADWZfck"
      },
      "source": [
        "'''\n",
        "Exercise: Implement iou(). Some hints:\n",
        "    In this exercise only, we define a box using its two corners (upper left and\n",
        "     lower right): (x1, y1, x2, y2) rather than the midpoint and height/width.\n",
        "    To calculate the area of a rectangle you need to multiply its height \n",
        "    (y2 - y1) by its width (x2 - x1)\n",
        "    You'll also need to find the coordinates (xi1, yi1, xi2, yi2) of the \n",
        "    intersection of two boxes. \n",
        "'''\n",
        "def iou(box1, box2):\n",
        "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (x1, y1, x2, y2)\n",
        "    box2 -- second box, list object with coordinates (x1, y1, x2, y2)\n",
        "    \"\"\"\n",
        "################################################################################\n",
        "# TODO: Replace \"None\" with the correct code/ logic to find IoU for the boxes. #\n",
        "# Remember to account for the case in which IoU is 0.                          #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    # Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1   #\n",
        "    # and box2. Calculate its Area.                                            #\n",
        "    xi1 = box1[0] if box2[0] <= box1[0] <= box2[2] else box2[0] if box1[0] <= box2[0] <= box1[2] else None\n",
        "    yi1 = box1[1] if box2[1] <= box1[1] <= box2[3] else box2[1] if box1[1] <= box2[1] <= box1[3] else None\n",
        "    xi2 = box1[2] if box2[0] <= box1[2] <= box2[2] else box2[2] if box1[0] <= box2[2] <= box1[2] else None\n",
        "    yi2 = box1[3] if box2[1] <= box1[3] <= box2[3] else box2[3] if box1[1] <= box2[3] <= box1[3] else None\n",
        "    # Case in which they don't intersec --> max(,0)\n",
        "    inter_area = (0 if xi1 is None or yi1 is None or xi2 is None or yi2 is None\n",
        "                  else (xi2 - xi1) * (yi2 - yi1))\n",
        "\n",
        "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "    return iou"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGwmWxFnPgaT"
      },
      "source": [
        "################################################################################\n",
        "# TODO: Replace \"None\" with the correct code/ logic to find IoU for the boxes. #\n",
        "# Perform iou on the test cases                                                #\n",
        "################################################################################\n",
        "iou_result_1 = iou(iou_test_case_1[0], iou_test_case_1[1])\n",
        "iou_result_2 = iou(iou_test_case_2[0], iou_test_case_2[1])\n",
        "iou_result_3 = iou(iou_test_case_3[0], iou_test_case_3[1])\n",
        "iou_result_4 = iou(iou_test_case_4[0], iou_test_case_4[1])\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcOsKGRmP2GN",
        "outputId": "5078f2f2-4c86-4e6d-d055-cff711151965"
      },
      "source": [
        "# Print out the test cases:\n",
        "print(\"IoU for 1st test case is:\", iou_result_1, \n",
        "      \"\\nIoU for 2nd test case is:\", iou_result_2, \n",
        "      \"\\nIoU for 3rd test case is:\", iou_result_3, \n",
        "      \"\\nIoU for 4th test case is:\", iou_result_4)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IoU for 1st test case is: 0.004039937669533099 \n",
            "IoU for 2nd test case is: 0.15201036013813518 \n",
            "IoU for 3rd test case is: -0.0 \n",
            "IoU for 4th test case is: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45hrkRJekb_"
      },
      "source": [
        "'''\n",
        "Exercise: Implement nms(). Some hints:\n",
        "    In this function, we will be performing non max suppression to select \n",
        "    bounding boxes for an object.\n",
        "    We will be assuming there is only one class of objects. However, the code is\n",
        "    is not very different for multiple classes of objects. \n",
        "    \n",
        "    c_score represents the confidence score of particular bounding box.\n",
        "\n",
        "    Use the iou function defined earlier.\n",
        "\n",
        "    Remember the algorithm to perform nms:\n",
        "    Discard all bounding boxes with confidence score < c_score_threshold\n",
        "    While there are any remaining boxes:\n",
        "      Pick box with largest confidence, output that as prediction.\n",
        "      Discard any remaining boxes with IoU > iou_threshold with the output box. \n",
        "\n",
        "    0.6 is an arbitrary number- feel free to experiment with it.\n",
        "\n",
        "    Make use of list comprehenion\n",
        "'''\n",
        "def nms(bboxes,iou_threshold,c_score_threshold):\n",
        "  '''\n",
        "    Implement non max supression given a list of bounding boxes.\n",
        "    Arguments:\n",
        "    bboxes: list of lists- the inner lists contain 5 elements and are of the\n",
        "            following format: [x1, y1, x2, y2, c_score]\n",
        "    iou_threshold: The threshold above which bounding boxes with lower confidence\n",
        "                    score are removed.\n",
        "    c_score_threshold: The minimum value of c_score below which bounding boxes\n",
        "                       are removed.\n",
        "    ''' \n",
        "################################################################################\n",
        "# TODO: Replace \"None\" with the correct code/ logic to find IoU for the boxes. #\n",
        "# Remember to account for the case in which IoU is 0.                          #\n",
        "################################################################################\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "  #Using list comprehension (or otherwise), select bounding boxes which have\n",
        "  # confidence score greater than c_score_threshold.\n",
        "  bboxes = [bbox for bbox in bboxes if bbox[4] >= c_score_threshold]\n",
        "\n",
        "  #Sort the bounding boxes in decreasing order of confidence score.\n",
        "  bboxes = sorted(bboxes, key=lambda bbox: -bbox[4]) # [:,:,-1]\n",
        "\n",
        "  #An empty list to store selected bounding boxes.\n",
        "  boxes_after_nms = []\n",
        "\n",
        "  #Loop through the bounding boxes\n",
        "  while bboxes:\n",
        "      #Select box with highest confidence score\n",
        "      chosen_box = bboxes[0]\n",
        "      #Using list comprehension (or otherwise), eliminate bounding boxes whose\n",
        "      #iou with \"chosen_box\" is greater than threshold.\n",
        "      bboxes = [bbox for bbox in bboxes[1:] if iou(bbox, chosen_box) < iou_threshold]\n",
        "      #Add the bbox with highest confidence score to the formerly created list.\n",
        "      boxes_after_nms.append(chosen_box)\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################\n",
        "  return boxes_after_nms"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyFjVHu9RMHW"
      },
      "source": [
        "################################################################################\n",
        "# TODO: Replace \"None\" with the correct code/ logic to find nms for the boxes. #\n",
        "# Perform nms on the test cases \n",
        "# Experiment with values for iou threshold and c_score threshold               #\n",
        "################################################################################\n",
        "nms_result_1 = nms(nms_test_case_1, 0.2, 0.6)\n",
        "nms_result_2 = nms(nms_test_case_2, 0.2, 0.6)\n",
        "nms_result_3 = nms(nms_test_case_3, 0.2, 0.6)\n",
        "nms_result_4 = nms(nms_test_case_4, 0.2, 0.6)\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTet-ea9Jyh-",
        "outputId": "858db047-fabc-4d80-c122-6a7d3b33ecc9"
      },
      "source": [
        "# Check the number of bounding boxes returned for eaach test case.\n",
        "print(\"Number of bounding boxes returned for 1st test case is: \", len(nms_result_1),\n",
        "      \"\\nNumber of bounding boxes returned for 2nd test case is: \", len(nms_result_2),\n",
        "      \"\\nNumber of bounding boxes returned for 3rd test case is: \", len(nms_result_3),\n",
        "      \"\\nNumber of bounding boxes returned for 4th test case is: \", len(nms_result_4))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of bounding boxes returned for 1st test case is:  1 \n",
            "Number of bounding boxes returned for 2nd test case is:  1 \n",
            "Number of bounding boxes returned for 3rd test case is:  2 \n",
            "Number of bounding boxes returned for 4th test case is:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "IQSVNBkqGs9f",
        "outputId": "96cd7d56-1366-42e6-f9e2-a135b9651097"
      },
      "source": [
        "# Depending on the number of bounding boxes, visualize the results. \n",
        "img = np.zeros([512,512,3], dtype = np.uint8)\n",
        "\n",
        "box = nms_result_1\n",
        "for i in range(len(nms_result_1)):\n",
        "    color = tuple(np.random.random(size=3) * 256)\n",
        "    cv2.rectangle(img, (box[i][0], box[i][1]), (box[i][2], box[i][3]), color)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAE0klEQVR4nO3VQQ2DABREQdpUAqowUW2YqCpE4KDpockPvBkFm728ZQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAruwxPYB7OrZ9esKVrJ/39ASAPxGA3/mKKc/pAQDMEACAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAICo1/QAbuvY9ukJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAX52ZLQoXTCM2kAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F6132185990>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_QBTJE6YbedA",
        "outputId": "2a9a8bf0-ab4e-474f-a4cf-6538e0396c32"
      },
      "source": [
        "img = np.zeros([512,512,3] ,dtype = np.uint8)\n",
        "box1, box2, box3, box4 = nms_test_case_3[0], nms_test_case_3[1], nms_test_case_3[2], nms_test_case_3[3]\n",
        "cv2.rectangle(img, (box1[0], box1[1]), (box1[2], box1[3]), color = (0,255,0))\n",
        "cv2.rectangle(img, (box2[0], box2[1]), (box2[2], box2[3]), color = (0,0,255))\n",
        "cv2.rectangle(img, (box3[0], box3[1]), (box3[2], box3[3]), color = (255,0,0))\n",
        "cv2.rectangle(img, (box4[0], box4[1]), (box4[2], box4[3]), color = (255,255,255)) \n",
        "cv2_imshow(img)\n",
        "\n",
        "img2 = np.zeros([512,512,3] ,dtype = np.uint8)\n",
        "box = nms_result_3\n",
        "for i in range(len(nms_result_3)):\n",
        "    color = tuple(np.random.random(size=3) * 256)\n",
        "    cv2.rectangle(img2, (box[i][0], box[i][1]), (box[i][2], box[i][3]), color)\n",
        "\n",
        "cv2_imshow(img2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAFWElEQVR4nO3dQW6DMBRAwVBx/yu7y0apSkKlxMCb2bL5sgwPeePbDQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgVcvsAYBjGrMHOBffUuA6BOB1Z12rr9kDADCHAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEStswcA5hjj6UWGZ73p8B2Wxa2/wFU8C4Cv/4+rrpUjIIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIWmcPcCpj9gCw1zJ7AA5MAHbyOnEiflnY5AgIIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgap09wLGM7cfLZ6aAHexK/k0AHm29TsPbxrE8+WWBTY6AAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAotbZA5zNmD0A3Fveuidt93sXXA0B2GOZPQD89q5tabvfG5dcEEdAAFECABAlAABRAgAQJQAAUQIAECUAAFECABAlAABRAgAQJQAAUQIAECUAAFECABAlAABRAgAQJQAAUQIAEOVKyEcXvPcT/jCG/Q4AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJ/zDR2sHrhpdPjhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F6132172090>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAAFLklEQVR4nO3dQW0CURhGUTpBAgawgJxKqCAkIAcLNYAG0j3pgqYl/0zvOQq+vGRyX95mdjsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgGe9TQ8A1mg5HaYnbMn9epueAPBHBOB52z2rZXoAADMEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAogQAIEoAAKIEACBKAACiBAAgSgAAovbTA9bleDlPT4Cf+Xz/mJ7AVgnAI58TG+LKwm94AgKIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIgSAIAoAQCIEgCAKAEAiBIAgCgBAIjaTw8AVmo5HaYn8FoCAHzjfr1NT+DlPAEBRAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlAAARAkAQJQAAEQJAECUAABECQBAlF9CPjpeztMTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+Ie+ABVhD69XZW/MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F6132172550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}